{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1cJ24xZWT-iX5i93c3qMcWIwLZbrWmGqj","authorship_tag":"ABX9TyOnjZvQqe9F7xxcBvrjzABQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# DeepLabCut for single animal tracking\n","\n","Some useful links:\n","\n","- [DeepLabCut's GitHub: github.com/DeepLabCut/DeepLabCut](https://github.com/DeepLabCut/DeepLabCut)\n","- [DeepLabCut's Documentation: User Guide for Single Animal projects](https://deeplabcut.github.io/DeepLabCut/docs/standardDeepLabCut_UserGuide.html)\n","\n","This notebook illustrates how to use the cloud to\n","- label data on DeepLabCut GUI\n","- create training set\n","- train a network\n","- evaluate a network\n","- analyze novel videos\n","\n","**This notebook is for user who do not have GPU computer.**\n","\n","Original Demo Notebook: https://deeplabcut.github.io/DeepLabCut/examples/COLAB/COLAB_DEMO_mouse_openfield.html\n","\n","*Modified by Do-young on 26.01.13*"],"metadata":{"id":"c1YY6c-DhJba"}},{"cell_type":"markdown","source":["# Step 1: Label Data on DeepLabCut GUI\n","1. Install DeepLabCut GUI\n","Open Anaconda Prompt\n","```python\n","conda create -n dlc python=3.9 -y\n","conda activate dlc\n","pip install \"deeplabcut[gui]\"\n","pip install \"deeplabcut[tf]\"\n","python -m deeplabcut\n","```\n","2. Create a new project\n","- Write 'project name' and 'Experimenter'\n","- Select folder that contains your videos and choose only 3-5 videos in the list.\n","- Click 'Copy videos to project folder'\n","3. Open `config.yaml` and fix the following part:\n","```\n","bodyparts:\n","- bodypart1\n","- bodypart2\n","- bodypart3\n","- objectA\n","```\n","For mouse with LED on its head, remove all the bodyparts and add LED\n","4. Extract frames\n","- Click 'Extract frames' banner\n","- Keep the default setting of 'Attributes'\n","- Change the video format to match with your videos\n","5. Label frames\n","- Click 'Label frames' banner\n","- Click 'Label frames' button\n","- Select folder with each videos one by one\n","\n","Then you will see another window named 'napari'\n","\n","- Adjust the point size\n","- Click the XOR button\n","- Click on the LED position\n","- Repeat for every frame\n","- Save (Ctrl+S)\n"],"metadata":{"id":"KbPZkBRjh2w5"}},{"cell_type":"markdown","source":["# Step 2: Colab Environment Setting\n","##1. Change Runtime Type\n","- Python3\n","- GPU\n"],"metadata":{"id":"aN2F4kEHs6vV"}},{"cell_type":"markdown","source":["## 2. Install DeepLabCut and TensorFlow"],"metadata":{"id":"acyODXumtk_0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"U_yDSjymmUnK"},"outputs":[],"source":["!pip install --pre deeplabcut"]},{"cell_type":"code","source":["import deeplabcut"],"metadata":{"id":"zwWgZZZcs790"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Link your Google Drive\n","- Make sure to upload the **project folder** of DeepLabCut that we stored the labels & **folder** with whole videos."],"metadata":{"id":"M8nknRDNtxpY"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"s-AqzwTYuM4n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PLEASE EDIT THIS:\n","project_folder_name = \"project_folder_name\"\n","video_type = \"avi\" #, mp4, MOV, or avi, whatever you uploaded!\n","\n","# No need to edit this, we are going to assume you put videos you want to analyze\n","# in the \"videos\" folder, but if this is NOT true, edit below:\n","videofile_path = [f\"/content/drive/My Drive/{project_folder_name}/videos/\"]\n","print(videofile_path)\n","\n","# The prediction files and labeled videos will be saved in this `labeled-videos` folder\n","# in your project folder; if you want them elsewhere, you can edit this;\n","# if you want the output files in the same folder as the videos, set this to an empty string.\n","destfolder = f\"/content/drive/My Drive/{project_folder_name}/labeled-videos\"\n","\n","#No need to edit this, as you set it when you passed the ProjectFolderName (above):\n","path_config_file = f\"/content/drive/My Drive/{project_folder_name}/config.yaml\"\n","print(path_config_file)\n","\n","# This creates a path variable that links to your Google Drive project"],"metadata":{"id":"ht0aIveguTnY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 3: Training\n","## 1. Create a training dataset"],"metadata":{"id":"JuOksgUbuf1K"}},{"cell_type":"code","source":["deeplabcut.create_training_dataset(\n","  path_config_file, net_type=\"resnet_50\", engine=deeplabcut.Engine.PYTORCH\n",")"],"metadata":{"id":"KMRntyhgulCx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Training\n","- Even though the 'Model performance' looks like this:\n","```\n","Model performance:\n","  metrics/test.rmse:            nan\n","  metrics/test.rmse_pcutoff:    nan\n","  metrics/test.mAP:            0.00\n","  metrics/test.mAR:            0.00\n","```\n","Don't worry, it's working well."],"metadata":{"id":"oBRrg02au7OR"}},{"cell_type":"code","source":["# Let's also change the display and save_epochs just in case Colab takes away\n","# the GPU... If that happens, you can reload from a saved point using the\n","# `snapshot_path` argument to `deeplabcut.train_network`:\n","#   deeplabcut.train_network(..., snapshot_path=\"/content/.../snapshot-050.pt\")\n","\n","# Typically, you want to train to ~200 epochs. We set the batch size to 8 to\n","# utilize the GPU's capabilities.\n","\n","# More info and there are more things you can set:\n","#   https://deeplabcut.github.io/DeepLabCut/docs/standardDeepLabCut_UserGuide.html#g-train-the-network\n","\n","deeplabcut.train_network(\n","    path_config_file,\n","    shuffle=1,\n","    save_epochs=5,\n","    epochs=200,\n","    batch_size=8,\n",")"],"metadata":{"id":"Kaj4aV9Su1nT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Evaluating\n","This function evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images) and stores the results as .csv file in a subdirectory under **evaluation-results-pytorch**"],"metadata":{"id":"G5GW55WvvNlE"}},{"cell_type":"code","source":["deeplabcut.evaluate_network(path_config_file, plotting=True)\n","\n","# Here you want to see a low pixel error! Of course, it can only be as\n","# good as the labeler, so be sure your labels are good!"],"metadata":{"id":"Otnk9jVuvXIQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 4: Analyze Videos (Model Application)\n","This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n","\n","The results are stored in hd5 file in the same directory where the video resides."],"metadata":{"id":"LqhGgLJHvdZz"}},{"cell_type":"code","source":["import glob\n","import os\n","\n","video_folder_path = '/content/drive/MyDrive/My_WebCam'\n","\n","all_videos = glob.glob(os.path.join(video_folder_path, '*.avi'))\n","all_videos.sort()\n","\n","print(f\" {len(all_videos)} videos found\")\n","\n","deeplabcut.analyze_videos(path_config_file, all_videos, save_as_csv=True)\n","\n","#outlier processing\n","deeplabcut.filterpredictions(path_config_file, all_videos, save_as_csv=True)"],"metadata":{"id":"_RpP4Kwbvrsr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Now you can look at the plot-poses file and check the \"plot-likelihood.png\" might want to change the \"p-cutoff\" in the config.yaml file so that you have only high confidnece points plotted in the video. i.e. ~0.8 or 0.9. The current default is 0.4."],"metadata":{"id":"7mKg2xXAwGvO"}},{"cell_type":"markdown","source":["## Merge csv files of each video\n","- In the directory where the video resides, csv files that contains LED x_coordinate & y_coordinate are saved.\n","- To generate the whole time scale position infomation csv file, run the following code"],"metadata":{"id":"bSW1W1SFwZXS"}},{"cell_type":"code","source":["import pandas as pd\n","import glob\n","import os\n","import re\n","\n","# 1. Edit path of folder where csv files are saved\n","csv_folder_path = '/content/drive/MyDrive/video_folder/'\n","\n","# 2. Find desired csv files (filtered version)\n","file_pattern = os.path.join(csv_folder_path, '*_filtered.csv')\n","all_files = glob.glob(file_pattern)\n","\n","# 3. Sort the csv in ascending order\n","def get_leading_number(filepath):\n","    filename = os.path.basename(filepath)\n","    match = re.match(r'^(\\d+)', filename)\n","    return int(match.group(1)) if match else -1\n","\n","all_files.sort(key=get_leading_number)\n","\n","print(f\"Total {len(all_files)}files found.\")\n","print(f\"First csv file: {os.path.basename(all_files[0])}\")\n","print(f\"Last csv file: {os.path.basename(all_files[-1])}\")\n","\n","# 4. Concatenate\n","df_list = []\n","\n","for file in all_files:\n","    # DLC CSV header: 3 column\n","    # DLC CSV 1st column: frame index\n","    df = pd.read_csv(file, header=[0, 1, 2], index_col=0)\n","    df_list.append(df)\n","\n","merged_df = pd.concat(df_list)\n","\n","# frame index adjustment\n","merged_df = merged_df.reset_index(drop=True)\n","\n","# 5. Save file\n","output_path = os.path.join(csv_folder_path, 'Final_Merged_Result.csv')\n","merged_df.to_csv(output_path)\n","\n","print(\"-\" * 30)\n","print(f\"Merge Completed. Saved in {output_path}\")\n","print(f\"Check the timeStamp.csv whether its index match with{len(merged_df)}\")"],"metadata":{"id":"Qh4pVn_Vw5PJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 5: Create Labeled video (Optional)\n","This function is for visualization purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides."],"metadata":{"id":"kBYD37OzwKIe"}},{"cell_type":"code","source":["deeplabcut.create_labeled_video(path_config_file, all_videos, filtered=True)"],"metadata":{"id":"gvtSK9wdwTMS"},"execution_count":null,"outputs":[]}]}